---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Jyotis Joy"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(lmtest)
install.packages("glmnet",repos = "http://cran.us.r-project.org")
library(glmnet)
library(rstatix)
```

##Introduction: 
```{r}
work_dir <-"/stor/home/jj37257/website/content/project"
affair <- read.csv("Affairs.csv")
affair$X <- NULL

```
This is the ‘affairs’ dataset, which is a dataset containing information on infidelity, known as Fair's Affairs. The data was attained using cross-section from a survey conducted by Psychology Today in 1969.  It contains the following variables: number of affairs, the person's gender and age,the number of years they were married, number of children they have,their religiousness, education level, occupation, and their rating of marriage. There are 601 observations and 9 variables in the data set.

##MANOVA Testing:
```{r}
library(rstatix)
t <- affair$gender
u <- affair%>% select(affairs, yearsmarried,age,rating)
sapply(split(u, t), mshapiro_test)
lapply(split(u,t), cov) 
box_m(u, t)

man1<-manova(cbind(affairs,yearsmarried,age,rating,education)~gender, data=affair)
summary(man1)
summary.aov(man1)
affair %>% group_by(gender) %>% summarize(mean(age), mean(education))
pairwise.t.test(affair$age,affair$gender, p.adj="none")
pairwise.t.test(affair$education,affair$gender, p.adj="none")
1 - (0.95^4)
0.05/10

```
Interpretation: 
A one-way MANOVA was conducted to determine the effect of gender (male or female) on five dependent variables (affairs,years married,age,rating, and education) Examination of formal test of multivariate normality assumption for each group showed normality for each group.Examination of covariance matrices for each group revealed relative homogeneity. No univariate or multivariate outliers were evident and MANOVA was considered to be an appropriate analysis technique.

Significant differences were found among gender for at least one of the dependent variables, Pillai trace= 0.20151, pseudoF= 30.032, p <0.0001.

Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for age and education were also significant with p < 0.0001. 

Post hoc analysis was performed conducting pairwise comparisons to determine which gender differed in age and education. Both genders were found to differ significantly from each other in terms of age and education after adjusting for multiple comparisons(bonferroni ).

I performed 1 MANOVA, 5 ANOVAs, and 4 t tests, so α = 0.05/10 as significance level. The probability of at least one type I error, unadjusted, is  0.1854938. The Bonferroni corrected significance level is  0.005. 

##Randomization:
```{r}
gen<-affair %>% select(gender,rating)
head(gen)
ggplot(gen,aes(rating,fill=gender))+geom_histogram(bins=6.5)+facet_wrap(~gender,ncol=2)
gen %>% group_by(gender) %>% summarize(means=mean(rating)) %>% summarize(mean_diff=diff(means)) %>% glimpse()

rand_dist<-vector() 
for(i in 1:5000){
  new<-data.frame(rating=sample(gen$rating),gen=gen$gender)
  rand_dist[i]<-mean(new[new$gen=="male",]$rating)
  mean(new[new$condition=="female",]$rating)}

{hist(rand_dist,main="",ylab="") ;  abline(v = c(-0.01660562, 0.01660562),col="red")}

mean(rand_dist>0.01660562 | rand_dist < -0.01660562)
mean(rand_dist>-0.01660562)*2

t.test(data=affair, rating~gender,)

```
Interpretation: 
Null Hypothesis: Mean rating of marriage is the same for both genders. 
Alternative Hypothesis: Mean rating of marriage is not the same for male and females.
Based on this test, we fail to reject the null hypothesis (p>0.05) that the group means are all equal. There is a probability of 0.8534 to get a mean difference if the outcome data was split into every possible random grouping. 

##Linear Regression Model:
```{r}
affair$age_r<-affair$age-mean(affair$age)
affair$yearsmarried_r<-affair$yearsmarried-mean(affair$yearsmarried)

fit<-lm(affairs~age_r+yearsmarried_r, data= affair)
summary(fit)
ggplot(affair,aes(y=age_r,x=yearsmarried_r,color=affairs))+geom_point()+stat_smooth(method="lm",se=FALSE)



fit2<-lm(affairs~age_r, data = affair)
summary(fit2)
ggplot(affair,aes(y=affairs,x=age_r))+geom_point()+stat_smooth(method="lm",se=FALSE)

fit3<-lm(affairs~yearsmarried_r, data = affair)
summary(fit3)
ggplot(affair,aes(y=affairs,x=yearsmarried_r))+geom_point()+stat_smooth(method="lm",se=FALSE)

fit4<-lm(affairs ~ age_r * yearsmarried_r, data=affair)
summary(fit4)

#Linearity 
resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')
fitted<-lm(affairs~age_r+yearsmarried_r, data= affair)$fitted.values
ggplot()+geom_point(aes(fitted,resids))

#Normality 
qqnorm(affair$age_r)
shapiro.test(head(affair$age_r))
qqnorm(affair$yearsmarried_r)
shapiro.test(head(affair$yearsmarried_r))

resids<-lm(affairs~age_r+yearsmarried_r, data= affair)$residuals
ggplot()+geom_histogram(aes(resids),bins=10)
ks.test(resids, "pnorm", mean=0, sd(resids))
shapiro.test(resids)

#Homoskedasticity
bptest(fit)
ggplot(affair,aes(age_r,yearsmarried_r,color=affairs))+geom_point()
library(sandwich)
library(lmtest)
fi<-lm(affairs~age_r+yearsmarried_r, data =  affair)
bptest(fit)

coeftest(fit)
coeftest(fit, vcov = vcovHC(fit))


```
Interpretation:

Predicted affairs for an average age with average years married is 1.646381. Controlling for years married, for every 1-unit increase in age, affairs goes down 0.027753 on average. Controlling for age, in persons of average years married, affairs are 0.152612 higher. Controlling for age, the slope for years married on affairs is 0.004742 less.

4.124% is the multiple r squared value and it is the proportion of variation in the outcome that is explained by my model. The adjusted r squared value says 3.804% of variability of affairs is explained (penalty to mitigate chance association).

Variance does not look pretty constant. In both formal tests of normality, we reject the null hypothesis that the true distribution is normal. Based on the Breusch-Pagan test, the p-Value < 0.05 indicates that the null hypothesis can not be rejected and therefore heteroskedasticity does not exists. With the robust standard errors, the t values decreased and the p-values increased. 

##Bootstrapped Standard errors:
```{r}

boot_sd<-affair[sample(nrow(affair),replace=TRUE),]

samp_distn<-replicate(1000, {
  boot_sd<-affair[sample(nrow(affair),replace=TRUE),]
  fit5<-lm(affairs ~ age_r * yearsmarried_r,data=boot_sd)
  coef(fit5)
  })

samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
summary(fit4)
coeftest(fit4, vcov = vcovHC(fit4))

```
Interpretation: 
The p-values for the corrected SEs are higher than the p-values of the uncorrected ones. Additionally the Std. Errors for the corrected SEs are also higher than the uncorrected ones.


##Logistic Regression Model:
```{r}
affair$y<-ifelse(affair$gender=="male",1,0)
fit5<-glm(y~age+children+occupation, data = affair, family=binomial(link="logit"))
summary(fit5)
exp(coef(fit5))

prob <- predict(fit5, data = affair, type = "response")
pred<-ifelse(prob>.5,1,0)
table(prediction=pred, truth = affair$y) %>% addmargins()

#Accuracy
(213+203)/601

#TPR
203/286

#TNR
213/315

#PPV
203/305

library(plotROC)
ROCplot<-ggplot(affair)+geom_roc(aes(d=y,m=prob), n.cuts=0)+  geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2) 
ROCplot
calc_auc(ROCplot)

class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}


k=10
data<-affair[sample(nrow(affair)),]
folds<-cut(seq(1:nrow(affair)),breaks=k,labels=F)

diags<-NULL 
for(i in 1:k){
  train<-data[folds!=i,]   
  test<-data[folds==i,]
  truth<-test$y
  fit6<-glm(y~age+children+occupation, data = affair, family = "binomial") 
  probs<-predict(fit6,newdata = test,type="response")
  diags<-rbind(diags,class_diag(probs,truth)) 
}

summarize_all(diags,mean)

affair$logit<-predict(fit5,type="link")
affair%>%ggplot()+geom_density(aes(logit,color=gender,fill=gender), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=gender))




```
Interpretation: 
Controlling for children and occupation, going up 1 age multiplies odds by a factor of 1.023. Controlling for age and occupation, going up 1 children multiplies odds by a factor of 1.445.Controlling for age and children, going up 1 occupation multiplies odds by a factor of 1.913.

Overall Accuracy (0.692) is just proportion of correctly classified cases.Sensitivity is the true positive rate (0.710) and it is the probability of correctly detecting a male based on age, children, and occupation.Specificity is the true negative rate (0.676) and it is the probability of correctly detecting a female based on age, children, and occupation. Precision ( 0.666) is the proportion classified as male actually being a male. The auc quantifies how well we are predicting overall and it is 0.614, which is poor since the rule of thumb for AUC is 0.6-0.7 is poor. It is hard to predict gender from just age, children, and occupation.

The ROC curve lets us visualize trade-off between sensitivity and specificity. After the fold classification diagnostics, the acc is 0.692, the sens is 0.710, the spec is 0.676, and the ppv is 0.665. The AUC actually increased a bit to 0.772 making it fair. 


##Logistic Regression from all variables:
```{r}

fit9<-glm(y~age+religiousness+occupation+rating, data = affair, family = binomial) 
prob<-predict(fit9,type="response")
class_diag(prob,affair$y)

k=10
data<-affair[sample(nrow(affair)),] 
folds<-cut(seq(1:nrow(affair)),breaks=k,labels=F)
diags<-NULL 
for(i in 1:k){
  train<-data[folds!=i,]   
  test<-data[folds==i,]
  truth<-test$y
  fit<-glm(y~age+religiousness+occupation+rating,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  diags<-rbind(diags,class_diag(probs,truth)) 
}
summarize_all(diags,mean)

x<-model.matrix(fit9)
y<-as.matrix(affair$y)
cv<-cv.glmnet(x,y,family = 'binomial')
lasso1<-glmnet(x,y,family = 'binomial',lambda=cv$lambda.1se)
coef(lasso1)


k=10
data<-affair[sample(nrow(affair)),] 
folds<-cut(seq(1:nrow(affair)),breaks=k,labels=F)
diags<-NULL 
for(i in 1:k){
  train<-data[folds!=i,]   
  test<-data[folds==i,]
  truth<-test$y
  fit<-glm(y~age+occupation,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  diags<-rbind(diags,class_diag(probs,truth)) 
}
summarize_all(diags,mean)
```
Interpretation: 
Overall Accuracy (0.684) is just proportion of correctly classified cases.Sensitivity is the true positive rate (0.745) and it is the probability of correctly detecting a male based on age, religiousness, occupation and rating.Specificity is the true negative rate (0.629) and it is the probability of correctly detecting a female based on age, religiousness, occupation and rating. Precision ( 0.645) is the proportion classified as male actually being a male. The auc quantifies how well we are predicting overall and it is 0.776, which is fair since the rule of thumb for AUC is 0.7-0.8 is fair It is somewhat hard to predict gender from just age, religiousness, occupation and rating.

After the fold classification diagnostics, the acc is 0.674, the sens is 0.755, the spec is 0.602, the ppv is 0.636 and the auc is 0.768. All of the diagnostics actually decreased when compared with the in-sample metrics. The model is not the best at predicting gender on new data. The drop in AUC from the original indicates slight overfitting!

The variables that were retained were age and occupation because they were the only variables that had a non zero value. These variables are most predictive of gender!

After the fold classification diagnostics on the lasso selected varibales, the acc is 0.671, the sens is 0.751, the spec is 0.600, the ppv is 0.637 and the auc is 0.776. Only the ppv and the auc increased when compared to the logistic regressions above whereas the other diagnostics decreased. Same story: the model is not the best at predicting gender on new data. The model makes better predictions on the new dataset (better CV AUC!).

